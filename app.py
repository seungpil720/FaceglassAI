import streamlit as st
import os
import cv2
import numpy as np
import requests
from PIL import Image
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# ==========================================
# 0. ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ
# ==========================================
st.set_page_config(page_title="AI Glasses Try-On", layout="wide")

@st.cache_resource
def load_detector():
    model_path = "face_landmarker.task"
    if not os.path.exists(model_path):
        url = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/latest/face_landmarker.task"
        with st.spinner("AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
            try:
                r = requests.get(url, timeout=30)
                with open(model_path, 'wb') as f:
                    f.write(r.content)
            except Exception as e:
                st.error(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                return None
    
    try:
        base_options = python.BaseOptions(model_asset_path=model_path)
        options = vision.FaceLandmarkerOptions(
            base_options=base_options,
            num_faces=1,
            output_face_blendshapes=False,
            output_facial_transformation_matrixes=False
        )
        return vision.FaceLandmarker.create_from_options(options)
    except Exception as e:
        st.error(f"ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

detector = load_detector()

# ==========================================
# 1. ëœë“œë§ˆí¬ & ì–¼êµ´ ë¶„ì„ í•¨ìˆ˜
# ==========================================
LM = {
    "forehead_top": 10, "chin": 152,
    "left_cheek": 234, "right_cheek": 454,
    "left_jaw": 172, "right_jaw": 397,
    "left_temple": 127, "right_temple": 356,
    "left_forehead": 71, "right_forehead": 301,
}
EYE = {"lo": 33, "li": 133, "ri": 362, "ro": 263}
NOSE = 168

VERY_SUITABLE_FRAMES = {
    "oval": ["cat-eye", "square", "aviator"],
    "round": ["square"],
    "square": ["round"],
    "heart": ["oval"],
    "triangle": ["oval", "round"],
}

def dist(a, b): return float(np.linalg.norm(a - b))

def angle(a, b, c):
    ba, bc = a - b, c - b
    cosv = np.dot(ba, bc) / (np.linalg.norm(ba)*np.linalg.norm(bc)+1e-6)
    return np.degrees(np.arccos(np.clip(cosv, -1, 1)))

def get_face_metrics(landmarks, w, h):
    def pt(i): return np.array([landmarks[i].x*w, landmarks[i].y*h], dtype=np.float32)

    face_h = dist(pt(LM["forehead_top"]), pt(LM["chin"]))
    cheek_w = dist(pt(LM["left_cheek"]), pt(LM["right_cheek"]))
    jaw_w = dist(pt(LM["left_jaw"]), pt(LM["right_jaw"]))
    upper_w = max(dist(pt(LM["left_temple"]), pt(LM["right_temple"])),
                  dist(pt(LM["left_forehead"]), pt(LM["right_forehead"])))

    ratio = face_h / (cheek_w + 1e-6)
    balance = 1 - (abs(upper_w - cheek_w) + abs(jaw_w - cheek_w)) / (2*cheek_w + 1e-6)
    jaw_ang = angle(pt(LM["left_cheek"]), pt(LM["left_jaw"]), pt(LM["chin"]))
    
    return ratio, balance, upper_w, jaw_w, jaw_ang

def classify_face_shape(ratio, balance, upper, jaw, jaw_ang):
    if ratio < 1.15 and balance > 0.9: return "round"
    if ratio > 1.28: return "oval"
    if jaw > upper: return "triangle"
    if upper > jaw: return "heart"
    if balance > 0.92 and jaw_ang > 150: return "square"
    return "oval"

def acuity_to_diopter(acuity):
    if acuity >= 1.0: return 0.0
    elif acuity >= 0.8: return -0.50
    elif acuity >= 0.6: return -1.00
    elif acuity >= 0.4: return -1.75
    elif acuity >= 0.3: return -2.50
    elif acuity >= 0.2: return -3.50
    elif acuity >= 0.1: return -5.00
    else: return -6.00

def check_frequency(avg_power):
    val = abs(avg_power)
    if val < 1.0: return "ì°©ìš© ë¹ˆë„ ë‚®ìŒ (í•„ìš”í•  ë•Œë§Œ ì°©ìš©)"
    elif val < 3.0: return "ì°©ìš© ë¹ˆë„ ì¤‘ê°„ (ìš´ì „Â·ìˆ˜ì—…Â·ì—…ë¬´ ì‹œ ì°©ìš© ê¶Œì¥)"
    elif val < 5.0: return "ì°©ìš© ë¹ˆë„ ë†’ìŒ (í•˜ë£¨ ëŒ€ë¶€ë¶„ ì°©ìš© í•„ìš”)"
    else: return "ì°©ìš© ë¹ˆë„ ë§¤ìš° ë†’ìŒ (ìƒì‹œ ì°©ìš© ê¶Œì¥)"

# ==========================================
# 2. ì´ë¯¸ì§€ ì²˜ë¦¬ (ì•ˆê²½ í•©ì„± ë¡œì§ ê°œì„ )
# ==========================================
def pil_to_bgra(pil_img):
    return cv2.cvtColor(np.array(pil_img.convert("RGBA")), cv2.COLOR_RGBA2BGRA)

def cleanup_glasses(bgra):
    # í°ìƒ‰ ë°°ê²½(JPG)ì„ íˆ¬ëª…í•˜ê²Œ ë³€í™˜
    b,g,r,a = cv2.split(bgra)
    # ë°ì€ ì˜ì—­ì„ íˆ¬ëª…í•˜ê²Œ
    mask = (b > 240) & (g > 240) & (r > 240)
    a[mask] = 0
    return cv2.merge([b,g,r,a])

def find_anchors_robust(bgra):
    """
    ì•ˆê²½ì˜ ì¢Œ/ìš° ë Œì¦ˆ ì¤‘ì‹¬ì„ ì°¾ìŠµë‹ˆë‹¤. 
    ì‹¤íŒ¨ ì‹œ ì´ë¯¸ì§€ ë¹„ìœ¨ ê¸°ë°˜ìœ¼ë¡œ ê°•ì œ ì„¤ì •í•©ë‹ˆë‹¤ (ë¬´í•œ ë¡œë”© ë°©ì§€).
    """
    h, w = bgra.shape[:2]
    alpha = bgra[:, :, 3]
    
    # 1. ì»¨íˆ¬ì–´ë¡œ ì°¾ê¸° ì‹œë„
    _, thresh = cv2.threshold(alpha, 10, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    pL, pR, pB = None, None, None

    if contours:
        # ë©´ì ìˆœ ì •ë ¬
        contours = sorted(contours, key=cv2.contourArea, reverse=True)
        if len(contours) >= 2:
            # ë©ì–´ë¦¬ê°€ 2ê°œ ì´ìƒ (ì•ˆê²½ì•Œ ë¶„ë¦¬í˜•)
            M1 = cv2.moments(contours[0])
            M2 = cv2.moments(contours[1])
            if M1["m00"] > 0 and M2["m00"] > 0:
                c1 = np.array([M1["m10"]/M1["m00"], M1["m01"]/M1["m00"]])
                c2 = np.array([M2["m10"]/M2["m00"], M2["m01"]/M2["m00"]])
                if c1[0] < c2[0]: pL, pR = c1, c2
                else: pL, pR = c2, c1
    
    # 2. ì‹¤íŒ¨í–ˆê±°ë‚˜(None), ë©ì–´ë¦¬ê°€ 1ê°œì¸ ê²½ìš° -> ê°•ì œ ì„¤ì • (Fallback)
    if pL is None:
        pL = np.array([w * 0.25, h * 0.5]) # ì™¼ìª½ 1/4 ì§€ì 
        pR = np.array([w * 0.75, h * 0.5]) # ì˜¤ë¥¸ìª½ 3/4 ì§€ì 
    
    pB = (pL + pR) / 2 # ë¸Œë¦¿ì§€ëŠ” ì¤‘ê°„
    return pL, pR, pB

def overlay_glasses(face_img, landmarks, glasses_bgra):
    h, w = face_img.shape[:2]
    
    def pt(idx): 
        return np.array([landmarks[idx].x * w, landmarks[idx].y * h], dtype=np.float32)

    # ì–¼êµ´ ê¸°ì¤€ì 
    f_L = pt(EYE["lo"])  # ì™¼ìª½ ëˆˆ ë°”ê¹¥
    f_R = pt(EYE["ro"])  # ì˜¤ë¥¸ìª½ ëˆˆ ë°”ê¹¥
    f_N = pt(NOSE)       # ì½”

    # ì•ˆê²½ ê¸°ì¤€ì 
    g_L, g_R, g_B = find_anchors_robust(glasses_bgra)
    
    # ë³€í™˜ ì¢Œí‘œ ê³„ì‚° (ëˆˆ ìœ„ì¹˜ë³´ë‹¤ ì‚´ì§ ë°”ê¹¥ìª½ìœ¼ë¡œ ì¡°ì •)
    eye_width = float(np.linalg.norm(f_L - f_R))
    
    # ëª©í‘œ ì¢Œí‘œ (ì–¼êµ´ ìœ„)
    # ëˆˆ ë„ˆë¹„ì˜ 10%ë§Œí¼ ë°”ê¹¥ìª½ìœ¼ë¡œ í™•ì¥í•´ì„œ ì•ˆê²½ì´ ëˆˆì„ ë®ë„ë¡ í•¨
    t_L = f_L + np.array([-eye_width * 0.15, 0])
    t_R = f_R + np.array([eye_width * 0.15, 0])
    t_B = f_N + np.array([0, -eye_width * 0.2]) # ì½”ë³´ë‹¤ ì•½ê°„ ìœ„

    src_pts = np.float32([g_L, g_R, g_B])
    dst_pts = np.float32([t_L, t_R, t_B])

    # Affine ë³€í™˜ í–‰ë ¬
    M = cv2.getAffineTransform(src_pts, dst_pts)
    
    # ì•ˆê²½ ì´ë¯¸ì§€ ë³€í˜•
    warped = cv2.warpAffine(
        glasses_bgra, M, (w, h), 
        flags=cv2.INTER_LINEAR, 
        borderMode=cv2.BORDER_CONSTANT, 
        borderValue=(0,0,0,0)
    )
    
    # í•©ì„± (Alpha Blending)
    # ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ BGRAë¡œ ë³€í™˜
    face_bgra = cv2.cvtColor(face_img, cv2.COLOR_BGR2BGRA)
    
    # ì•ŒíŒŒ ì±„ë„ ì •ê·œí™” (0~1)
    alpha = warped[:, :, 3] / 255.0
    alpha = np.dstack([alpha, alpha, alpha]) # 3ì±„ë„ë¡œ ë§ì¶¤ (BGR ëŒ€ìƒ)

    # ì „ê²½(ì•ˆê²½)ê³¼ ë°°ê²½(ì–¼êµ´) í•©ì„±
    fg = warped[:, :, :3]
    bg = face_bgra[:, :, :3]
    
    out = (fg * alpha + bg * (1.0 - alpha)).astype(np.uint8)
    return out

# ==========================================
# 3. ë©”ì¸ UI (ë ˆì´ì•„ì›ƒ ìˆ˜ì •)
# ==========================================
st.title("ğŸ‘“ AI Smart Glasses Fitting")
st.markdown("ì„œë²„ì— ì €ì¥ëœ **ì–¼êµ´ ì‚¬ì§„**ì„ ë¶„ì„í•˜ê³  **ì•ˆê²½**ì„ ê°€ìƒìœ¼ë¡œ ì°©ìš©í•´ë³´ì„¸ìš”.")

# íŒŒì¼ ëª©ë¡ ë¡œë“œ
try:
    all_files = os.listdir('.')
    img_exts = ('.png', '.jpg', '.jpeg', '.webp')
    
    # í‚¤ì›Œë“œë¡œ ì•ˆê²½/ì–¼êµ´ íŒŒì¼ ë¶„ë¥˜
    glasses_keywords = ['glass', 'eye', 'aviator', 'round', 'square']
    
    glasses_files = sorted([f for f in all_files if any(k in f.lower() for k in glasses_keywords) and f.endswith(img_exts)])
    face_files = sorted([f for f in all_files if f not in glasses_files and f.endswith(img_exts)])
except:
    glasses_files = []
    face_files = []

col1, col2 = st.columns(2)

# [ì™¼ìª½] ì–¼êµ´ ì„ íƒ ë° ë¶„ì„ ê²°ê³¼
with col1:
    st.header("1. ì–¼êµ´ ë¶„ì„ (Face Analysis)")
    
    # ì‹œë ¥ ì…ë ¥
    c1, c2 = st.columns(2)
    with c1: l_eye = st.number_input("ì¢Œì•ˆ ì‹œë ¥", 0.1, 2.0, 0.5, 0.1)
    with c2: r_eye = st.number_input("ìš°ì•ˆ ì‹œë ¥", 0.1, 2.0, 0.5, 0.1)

    if face_files:
        selected_face = st.selectbox("ì–¼êµ´ ì‚¬ì§„ ì„ íƒ", face_files)
        
        if selected_face:
            # ì´ë¯¸ì§€ ë¡œë“œ
            face_pil = Image.open(selected_face).convert("RGB")
            # ë¯¸ë¦¬ë³´ê¸°ìš© ë¦¬ì‚¬ì´ì¦ˆ (ì†ë„ í–¥ìƒ)
            face_pil.thumbnail((600, 600)) 
            face_cv2 = cv2.cvtColor(np.array(face_pil), cv2.COLOR_RGB2BGR)
            h, w = face_cv2.shape[:2]

            # ëœë“œë§ˆí¬ ê²€ì¶œ
            mp_img = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.cvtColor(face_cv2, cv2.COLOR_BGR2RGB))
            result = detector.detect(mp_img)

            if result.face_landmarks:
                lm = result.face_landmarks[0]
                
                # ë¶„ì„ ìˆ˜í–‰
                r, b, u, j, ang = get_face_metrics(lm, w, h)
                shape = classify_face_shape(r, b, u, j, ang)
                recs = VERY_SUITABLE_FRAMES.get(shape, ["square"])
                
                avg_d = (acuity_to_diopter(l_eye) + acuity_to_diopter(r_eye)) / 2
                freq = check_frequency(avg_d)

                # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                st.success(f"**ì–¼êµ´í˜•:** {shape.upper()}")
                st.info(f"**ì¶”ì²œ ì•ˆê²½:** {', '.join(recs).upper()}")
                st.warning(f"**{freq}**")
                
                # ì–¼êµ´ ì´ë¯¸ì§€ í‘œì‹œ
                st.image(face_pil, caption="ë¶„ì„ëœ ì–¼êµ´", use_container_width=True)
            else:
                st.error("ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ì–¼êµ´ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

# [ì˜¤ë¥¸ìª½] ì•ˆê²½ ì„ íƒ ë° ê°€ìƒ í”¼íŒ…
with col2:
    st.header("2. ê°€ìƒ í”¼íŒ… (Virtual Try-On)")
    
    if glasses_files:
        selected_glass = st.selectbox("ì•ˆê²½ ì„ íƒ", glasses_files)
        
        # ë²„íŠ¼ì„ ëˆ„ë¥´ê±°ë‚˜ ì„ íƒí•˜ë©´ ìë™ ì‹¤í–‰
        if selected_glass and 'face_cv2' in locals() and 'lm' in locals():
            st.write("â–¼ ì•„ë˜ì—ì„œ ì°©ìš© ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            try:
                with st.spinner("ì•ˆê²½ ì°©ìš© ì¤‘..."):
                    # ì•ˆê²½ ì´ë¯¸ì§€ ë¡œë“œ
                    g_pil = Image.open(selected_glass).convert("RGBA")
                    g_bgra = pil_to_bgra(g_pil)
                    g_bgra = cleanup_glasses(g_bgra) # ì „ì²˜ë¦¬
                    
                    # í•©ì„± ìˆ˜í–‰ (robust í•¨ìˆ˜ ì‚¬ìš©ìœ¼ë¡œ ë©ˆì¶¤ ë°©ì§€)
                    final_bgr = overlay_glasses(face_cv2, lm, g_bgra)
                    
                    # ê²°ê³¼ í‘œì‹œ
                    final_rgb = cv2.cvtColor(final_bgr, cv2.COLOR_BGR2RGB)
                    st.image(final_rgb, caption=f"ì°©ìš© ê²°ê³¼: {selected_glass}", use_container_width=True)
            
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        st.warning("ì•ˆê²½ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
