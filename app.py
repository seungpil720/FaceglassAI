import streamlit as st
import os
import cv2
import numpy as np
import requests
from PIL import Image
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# ==========================================
# 0. ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ
# ==========================================
st.set_page_config(page_title="AI Glasses Try-On", layout="wide")

@st.cache_resource
def load_detector():
    model_path = "face_landmarker.task"
    if not os.path.exists(model_path):
        url = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/latest/face_landmarker.task"
        with st.spinner("AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
            try:
                r = requests.get(url, timeout=30)
                with open(model_path, 'wb') as f:
                    f.write(r.content)
            except Exception as e:
                st.error(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                return None
    
    try:
        base_options = python.BaseOptions(model_asset_path=model_path)
        options = vision.FaceLandmarkerOptions(
            base_options=base_options,
            num_faces=1,
            output_face_blendshapes=False,
            output_facial_transformation_matrixes=False
        )
        return vision.FaceLandmarker.create_from_options(options)
    except Exception as e:
        st.error(f"ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

detector = load_detector()

# ==========================================
# 1. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ì¢Œí‘œ, ê°ë„ ë“±)
# ==========================================
LM = { "chin": 152, "left_temple": 127, "right_temple": 356, "nose": 168 }
EYE = { "left": 33, "right": 263 }

def dist(a, b):
    return float(np.linalg.norm(a - b))

def get_landmark_point(landmarks, idx, w, h):
    return np.array([landmarks[idx].x * w, landmarks[idx].y * h], dtype=np.float32)

# ==========================================
# 2. ì•ˆê²½ ì´ë¯¸ì§€ ì²˜ë¦¬ (í•µì‹¬ ë¡œì§)
# ==========================================
def pil_to_bgra(pil_image):
    return cv2.cvtColor(np.array(pil_image.convert("RGBA")), cv2.COLOR_RGBA2BGRA)

def cleanup_glasses_image(bgra):
    # í°ìƒ‰ ë°°ê²½ ì œê±° (JPG ëŒ€ì‘)
    b, g, r, a = cv2.split(bgra)
    # ë°ê¸°ê°€ ë§¤ìš° ë°ì€ ì˜ì—­(í°ìƒ‰)ì„ íˆ¬ëª…í•˜ê²Œ ì²˜ë¦¬
    mask = (b > 240) & (g > 240) & (r > 240)
    a[mask] = 0
    return cv2.merge([b, g, r, a])

def find_glasses_anchors(bgra):
    """
    ì•ˆê²½ ì´ë¯¸ì§€ì—ì„œ ì¢Œ/ìš° ë Œì¦ˆ ì¤‘ì‹¬ê³¼ ë¸Œë¦¿ì§€(ì½”) ìœ„ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    ì‹¤íŒ¨ ì‹œ ì´ë¯¸ì§€ í¬ê¸° ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •ì¹˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤ (ë¬´í•œ ë¡œë”© ë°©ì§€).
    """
    h, w = bgra.shape[:2]
    alpha = bgra[:, :, 3]
    
    # íˆ¬ëª…ë„ê°€ ì•„ë‹Œ ì˜ì—­ ì°¾ê¸°
    _, thresh = cv2.threshold(alpha, 10, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # ì»¨íˆ¬ì–´ê°€ ê°ì§€ë˜ë©´ ë Œì¦ˆ ìœ„ì¹˜ ê³„ì‚° ì‹œë„
    if contours:
        # ë©´ì ì´ í° ìˆœì„œëŒ€ë¡œ ì •ë ¬
        contours = sorted(contours, key=cv2.contourArea, reverse=True)
        
        # ë©ì–´ë¦¬ê°€ 2ê°œ ì´ìƒì´ë©´ (ì–‘ìª½ ë Œì¦ˆê°€ ë¶„ë¦¬ëœ ê²½ìš°)
        if len(contours) >= 2:
            M1 = cv2.moments(contours[0])
            M2 = cv2.moments(contours[1])
            if M1["m00"] != 0 and M2["m00"] != 0:
                c1 = np.array([M1["m10"] / M1["m00"], M1["m01"] / M1["m00"]])
                c2 = np.array([M2["m10"] / M2["m00"], M2["m01"] / M2["m00"]])
                
                # ì¢Œìš° ì •ë ¬
                if c1[0] < c2[0]: pL, pR = c1, c2
                else: pL, pR = c2, c1
                
                pB = (pL + pR) / 2  # ì¤‘ê°„ì§€ì (ë¸Œë¦¿ì§€)
                return pL, pR, pB

    # [Fallback] ì»¨íˆ¬ì–´ ê°ì§€ ì‹¤íŒ¨í•˜ê±°ë‚˜ ë©ì–´ë¦¬ê°€ 1ê°œì¸ ê²½ìš° (í…Œê°€ ì´ì–´ì§„ ì•ˆê²½)
    # ì´ë¯¸ì§€ì˜ 1/4, 3/4 ì§€ì ì„ ë Œì¦ˆ ì¤‘ì‹¬ìœ¼ë¡œ ê°€ì •
    pL = np.array([w * 0.25, h * 0.5])
    pR = np.array([w * 0.75, h * 0.5])
    pB = np.array([w * 0.50, h * 0.5])
    return pL, pR, pB

def overlay_glasses(face_img, landmarks, glasses_bgra):
    h, w = face_img.shape[:2]
    
    # 1. ì–¼êµ´ ê¸°ì¤€ ì¢Œí‘œ ê³„ì‚°
    face_L = get_landmark_point(landmarks, EYE["left"], w, h)
    face_R = get_landmark_point(landmarks, EYE["right"], w, h)
    face_N = get_landmark_point(landmarks, LM["nose"], w, h)
    
    # 2. ì•ˆê²½ ê¸°ì¤€ ì¢Œí‘œ ê³„ì‚° (ì‹¤íŒ¨ ì—†ëŠ” í•¨ìˆ˜ í˜¸ì¶œ)
    glass_L, glass_R, glass_B = find_glasses_anchors(glasses_bgra)
    
    # 3. í¬ê¸° ë° íšŒì „ ê³„ì‚° (Affine Transform)
    # ì†ŒìŠ¤ ì¢Œí‘œ (ì•ˆê²½)
    src_pts = np.float32([glass_L, glass_R, glass_B])
    # íƒ€ê²Ÿ ì¢Œí‘œ (ì–¼êµ´) - ëˆˆ ìœ„ì¹˜ë³´ë‹¤ ì•½ê°„ ì•„ëž˜, ì½” ìœ„ì¹˜ ê³ ë ¤
    face_width = dist(face_L, face_R)
    # ì•ˆê²½ì´ ëˆˆë³´ë‹¤ ì•½ê°„ ì»¤ì•¼ í•˜ë¯€ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •
    
    # ë¯¸ì„¸ ì¡°ì • íŒŒë¼ë¯¸í„°
    target_L = face_L + np.array([-face_width * 0.1, 0]) 
    target_R = face_R + np.array([face_width * 0.1, 0])
    target_B = face_N + np.array([0, -face_width * 0.15]) # ì½”ë³´ë‹¤ ì•½ê°„ ìœ„

    dst_pts = np.float32([target_L, target_R, target_B])
    
    # ë³€í™˜ í–‰ë ¬ ê³„ì‚°
    matrix = cv2.getAffineTransform(src_pts, dst_pts)
    
    # ì•ˆê²½ ì´ë¯¸ì§€ ë³€í˜•
    warped_glasses = cv2.warpAffine(
        glasses_bgra, matrix, (w, h), 
        flags=cv2.INTER_LINEAR, 
        borderMode=cv2.BORDER_CONSTANT, 
        borderValue=(0,0,0,0)
    )
    
    # 4. í•©ì„± (Alpha Blending)
    face_bgra = cv2.cvtColor(face_img, cv2.COLOR_BGR2BGRA)
    
    # ì•ŒíŒŒ ì±„ë„ ì •ê·œí™” (0~1)
    alpha_mask = warped_glasses[:, :, 3] / 255.0
    alpha_mask = np.dstack([alpha_mask] * 3) # 3ì±„ë„ë¡œ í™•ìž¥
    
    # í•©ì„± ê³µì‹: (ì•ˆê²½ * ì•ŒíŒŒ) + (ì–¼êµ´ * (1-ì•ŒíŒŒ))
    foreground = warped_glasses[:, :, :3]
    background = face_bgra[:, :, :3]
    
    combined = (foreground * alpha_mask + background * (1.0 - alpha_mask)).astype(np.uint8)
    return combined

# ==========================================
# 3. ë©”ì¸ UI
# ==========================================
st.title("ðŸ‘“ AI Smart Glasses Fitting")
st.write("ì„œë²„ì— ì—…ë¡œë“œëœ ì‚¬ì§„ì„ ì„ íƒí•˜ì—¬ ì•ˆê²½ì„ ì°©ìš©í•´ ë³´ì„¸ìš”.")

# íŒŒì¼ ëª©ë¡ ë¡œë“œ
try:
    all_files = os.listdir('.')
    img_exts = ('.png', '.jpg', '.jpeg', '.webp')
    
    # íŒŒì¼ëª…ì— 'glass'ê°€ í¬í•¨ë˜ë©´ ì•ˆê²½, ì•„ë‹ˆë©´ ì–¼êµ´ë¡œ ê°„ë‹¨ ë¶„ë¥˜
    glasses_files = sorted([f for f in all_files if 'glass' in f.lower() and f.endswith(img_exts)])
    # glassesê°€ ì•„ë‹ˆê³ , íŒŒì´ì¬/í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì•„ë‹Œ ê²ƒë“¤ì„ ì–¼êµ´ ì‚¬ì§„ìœ¼ë¡œ ê°„ì£¼
    face_files = sorted([f for f in all_files if f not in glasses_files and f.endswith(img_exts)])
    
except Exception as e:
    st.error(f"íŒŒì¼ ëª©ë¡ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    glasses_files = []
    face_files = []

col1, col2 = st.columns(2)

with col1:
    st.subheader("1. ì–¼êµ´ ì‚¬ì§„ ì„ íƒ")
    if face_files:
        selected_face = st.selectbox("ì–¼êµ´ ì´ë¯¸ì§€", face_files)
        if selected_face:
            face_pil = Image.open(selected_face).convert('RGB')
            face_cv2 = cv2.cvtColor(np.array(face_pil), cv2.COLOR_RGB2BGR)
            st.image(face_pil, caption="ì„ íƒëœ ì–¼êµ´", use_container_width=True)
    else:
        st.warning("ì–¼êµ´ ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤. (.jpg, .png ë“±)")

with col2:
    st.subheader("2. ì•ˆê²½ ì„ íƒ ë° ê²°ê³¼")
    if glasses_files:
        selected_glass = st.selectbox("ì•ˆê²½ ì´ë¯¸ì§€", glasses_files)
        
        if selected_glass and 'face_cv2' in locals():
            if st.button("ì•ˆê²½ ì°©ìš©í•˜ê¸° (Click to Try-On)"):
                with st.spinner("AIê°€ ì•ˆê²½ì„ ì”Œìš°ëŠ” ì¤‘ìž…ë‹ˆë‹¤..."):
                    try:
                        # 1. ì•ˆê²½ ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
                        glass_pil = Image.open(selected_glass).convert("RGBA")
                        glass_bgra = pil_to_bgra(glass_pil)
                        glass_bgra = cleanup_glasses_image(glass_bgra)
                        
                        # 2. ì–¼êµ´ ëžœë“œë§ˆí¬ ê²€ì¶œ
                        mp_img = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.cvtColor(face_cv2, cv2.COLOR_BGR2RGB))
                        detection_result = detector.detect(mp_img)
                        
                        if detection_result.face_landmarks:
                            # 3. í•©ì„± ìˆ˜í–‰
                            landmarks = detection_result.face_landmarks[0]
                            final_img = overlay_glasses(face_cv2, landmarks, glass_bgra)
                            
                            # 4. ê²°ê³¼ ì¶œë ¥
                            st.image(cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB), caption="ì°©ìš© ê²°ê³¼", use_container_width=True)
                        else:
                            st.error("ì‚¬ì§„ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            
                    except Exception as e:
                        st.error(f"í•©ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        # ë””ë²„ê¹…ì„ ìœ„í•´ ì—ëŸ¬ ìƒì„¸ ì¶œë ¥
                        import traceback
                        st.text(traceback.format_exc())
    else:
        st.warning("ì•ˆê²½ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. (íŒŒì¼ëª…ì— 'glass' í¬í•¨ í•„ìš”)")
